# 全参数微调科普版

> 面向零基础读者的全参数微调入门指南

## 一句话概括

**全参数微调就是把大模型的所有参数都重新训练一遍，让它完全适应新任务。**

## 从一个问题开始

想象你有一个全能的 AI 助手，它什么都知道一点。但是你希望它：

- 成为医学专家
- 学会用法律术语说话
- 掌握你们公司的内部知识

最直接的方法是什么？**把它的"大脑"彻底改造一遍！**

这就是全参数微调做的事情。

## 什么是全参数微调？

全参数微调（Full Fine-tuning）是指在预训练模型的基础上，使用特定任务的数据，**更新模型的所有参数**。

### 生活中的类比

想象你有一个通用技能的员工：

- **预训练**：员工在大学里学了各种基础知识
- **全参数微调**：把他送到专业培训机构，从头到尾重新培训

结果：他变成了一个专业人才，但可能忘记了之前的一些通用技能。

## 与 LoRA 的对比

| 特性 | 全参数微调 | LoRA |
|------|-----------|------|
| 训练参数量 | 100% | ~1% |
| 显存需求 | 非常高 | 较低 |
| 训练时间 | 长 | 短 |
| 效果上限 | 最高 | 接近全参数 |
| 灾难性遗忘风险 | 高 | 低 |
| 存储成本 | 每个版本一个完整模型 | 只需存小适配器 |

## 全参数微调的流程

```mermaid
flowchart LR
    A[预训练模型] --> B[准备任务数据]
    B --> C[训练所有参数]
    C --> D[得到微调模型]
    D --> E[部署使用]
```

### 简单来说

1. **加载预训练模型**：比如 GPT、LLaMA
2. **准备你的数据**：特定领域的问答、文章等
3. **训练所有参数**：让模型适应你的任务
4. **保存新模型**：得到一个专门化的大模型

## 优点

- **效果最好**：所有参数都能调整，理论上能学到最多
- **知识融合深入**：新知识和原有知识深度融合
- **适合大变化**：任务与预训练差异大时效果好

## 缺点

### 太贵了

| 模型规模 | 全参数微调显存 | 大约成本 |
|----------|---------------|----------|
| 7B | ~60GB | 单卡 A100 |
| 13B | ~120GB | 2x A100 |
| 70B | ~600GB | 8x A100 |
| 175B | ~1500GB | 多机集群 |

### 灾难性遗忘

模型可能"学了新的，忘了旧的"：

- 原来会写代码，微调后可能变差了
- 原来会多语言，微调后可能只懂一种了

### 存储问题

每个微调版本都是一个完整的模型：

- 10 个微调版本 = 10 个 70GB 的文件
- LoRA 只需要 10 个几百 MB 的适配器

## 什么时候用全参数微调？

**推荐用：**
- 任务与预训练差异巨大（比如医学、法律专业领域）
- 追求极致效果
- 有充足的计算资源

**不推荐用：**
- 只是小范围调整（用 LoRA 更好）
- 资源有限
- 需要多个定制版本

## 实际案例

### 成功案例：InstructGPT

OpenAI 使用全参数微调 + 人类反馈（RLHF），让 GPT 学会遵循指令。

### 成功案例：医学大模型

在医学文献上全参数微调，模型能准确回答医学问题。

## 你需要记住的

| 概念 | 通俗理解 |
|------|----------|
| 全参数微调 | 把模型所有参数都重新训练 |
| 灾难性遗忘 | 学了新的，忘了旧的 |
| 预训练模型 | 通用知识的"大学毕业生" |
| 微调后的模型 | 专业培训后的"专家" |

## 下一步

- 想了解技术细节？阅读 [深入版](advanced-guide.md)
- 想看代码实现？查看 `examples/` 目录
- 想看流程图？查看 [流程图解](diagram.md)
