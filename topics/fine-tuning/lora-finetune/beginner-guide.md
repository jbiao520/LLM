# LoRA 微调科普版

> 面向零基础读者的 LoRA 微调入门指南

## 一句话概括

**LoRA 就像是给大模型装了一个"小插件"，只需要训练很少的参数，就能让模型学会新技能。**

## 从一个问题开始

想象你买了一台非常昂贵的智能手机（就像 GPT-4 这样的超大模型），它什么都会。但是现在你想让它：

- 用你们公司的专业术语回答问题
- 用特定的语气写邮件
- 专门解答医学问题

你怎么办？把整个手机拆开重新组装？那太贵了，而且可能弄坏。

**能不能只加一个小配件，就让手机获得新功能？**

这就是 LoRA ���解决的问题！

## 传统方法：全参数微调

传统做法是把模型的**所有参数**都重新训练一遍。

### 问题来了

| 问题 | 具体情况 |
|------|----------|
| 太贵了 | GPT-3 有 1750 亿个参数，全训练需要几百万美元 |
| 存不下 | 每个微调版本都要保存一份完整模型，硬盘爆炸 |
| 容易忘 | 训练太狠，模型可能把原来会的都忘了（灾难性遗忘）|

## LoRA 的聪明做法

LoRA 的核心思想：**不改动原来的参数，只在旁边加一小部分新参数。**

### 生活中的类比

想象你有一本教科书（原始模型）：

- **全参数微调**：把整本书都擦掉，重新写一遍
- **LoRA**：在书旁边贴便利贴，新知识写在便利贴上

用的时候，看书的内容 + 便利贴的内容 = 定制版知识

### 技术原理（极简版）

模型中的权重矩阵 $W$，LoRA 不直接改它，而是：

$$W_{new} = W + BA$$

其中：
- $W$：原始权重（冻结，不训练）
- $B$ 和 $A$：两个小矩阵（这就是我们要训练的"便利贴"）

这两个小矩阵有多小呢？通常是原矩阵的 **1% 到 0.1%**！

## 实际效果对比

| 方法 | 可训练参数 | 显存需求 | 训练速度 |
|------|-----------|----------|----------|
| 全参数微调 | 100% | 非常高 | 慢 |
| LoRA | ~1% | 低很多 | 快 |
| QLoRA | ~1% | 最低 | 快 |

## QLoRA 是什么？

QLoRA = Quantized LoRA（量化 LoRA）

就是在 LoRA 的基础上，再把原始模型压缩一下：

- 用 4-bit 存储基础模型（原本是 16-bit）
- 训练时再解压
- 效果几乎一样，但显存需求更低了

**一句话：QLoRA 让普通显卡也能微调大模型。**

## 你需要记住的

| 概念 | 通俗理解 |
|------|----------|
| LoRA | 给模型贴便利贴，只训练便利贴 |
| Rank (r) | 便利贴的"容量"，越大能学的东西越多，但也越贵 |
| Alpha | 便利贴的"影响力"，控制新知识的强度 |
| QLoRA | 压缩版 LoRA，更省资源 |

## 什么时候用 LoRA？

**推荐用：**
- 个人/小团队微调大模型
- 显存有限（比如只有一张消费级显卡）
- 需要训练多个定制版本

**不推荐用：**
- 需要模型学习全新的知识体系
- 预算充足，追求极致效果
- 任务与预训练差异巨大

## 下一步

- 想了解数学原理？阅读 [深入版](advanced-guide.md)
- 想看代码实现？查看 `examples/` 目录
- 想看流程图？查看 [流程图解](diagram.md)
