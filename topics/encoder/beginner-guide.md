# 编码器（Encoder）科普版

> 面向零基础读者的编码器入门指南

## 一句话概括

**编码器就像一个"阅读理解专家"，把一段文字"读懂"并转化为计算机能理解的深层表示。**

## 从一个问题开始

想象你要向一个不懂英语的朋友解释一篇文章的内容：

1. 你需要先**读懂**这篇文章
2. 理解每个词、每句话的含义
3. 把理解到的内容"编码"成朋友能理解的形式

这就是**编码器**做的事情：把原始输入（文字、图像等）转化为机器能理解的"深层表示"。

## 核心概念

### 什么是"编码"？

编码就是把信息从一种形式转换为另一种形式。

例子：
- 摩斯密码：把字母转换成点和划
- 条形码：把商品信息转换成黑白条纹
- 编码器：把文字转换成数值向量

### 编码器的特点

1. **双向理解**：能看到整个句子，理解上下文
2. **逐层抽象**：从词到短语到句子，层层深入
3. **位置感知**：知道每个词在句子中的位置

## Transformer 编码器

### 结构

一个 Transformer 编码器由多个相同的层堆叠而成，每层包含：

```
输入 → [Self-Attention] → [Add & Norm] → [FFN] → [Add & Norm] → 输出
```

### 各部分作用

| 组件 | 作用 | 通俗理解 |
|------|------|----------|
| Self-Attention | 理解词与词之间的关系 | "他"指的是谁？ |
| LayerNorm | 稳定数值 | 保持数据在合理范围 |
| FFN | 非线性变换 | 提取更深层的特征 |
| 残差连接 | 帮助梯度流动 | 保留原始信息 |

## 编码器的应用

### BERT

最著名的编码器模型，用于：
- 文本分类：判断一段话的情感
- 命名实体识别：找出句子中的人名、地名
- 问答系统：从文章中找答案

### 为什么用编码器？

编码器能看到整个输入，所以特别适合：
- **理解任务**：需要"读懂"整个内容
- **分类任务**：判断输入属于哪一类
- **标注任务**：给每个词打标签

## 编码器 vs 解码器

| 特点 | 编码器 | 解码器 |
|------|--------|--------|
| 看的方向 | 双向（前后都看） | 单向（只看前面） |
| 典型任务 | 理解、分类 | 生成、翻译 |
| 代表模型 | BERT | GPT |

## 一个直观的例子

输入句子："苹果公司发布了新手机"

编码器的处理过程：

1. **第1层**：理解基本词义
   - 苹果 → 公司（而不是水果）
   - 发布 → 动作

2. **第2层**：理解词间关系
   - "苹果公司"是发布者
   - "新手机"是被发布的

3. **第3层**：理解整体含义
   - 这是一条科技新闻
   - 关于产品发布

最终输出：每个词都有一个"深层表示"，包含了上下文信息。

## 总结

| 概念 | 通俗理解 |
|------|----------|
| 编码器 | 把输入"读懂"并转化成深层表示 |
| 双向理解 | 前后文都能看到 |
| Self-Attention | 理解词与词的关系 |
| 堆叠层 | 逐层加深理解 |

## 下一步

- 想了解数学原理？阅读 [深入版](advanced-guide.md)
- 想看代码实现？查看 `examples/` 目录
